{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1627471865625,"user":{"displayName":"장수완","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcHOjw1DJMH5S_Hl_Wuh_QCdDQy5hTTbQHK9YHDEQ=s64","userId":"01976359756172135532"},"user_tz":-540},"id":"ySUoestWhXdn","outputId":"11c32f4d-b93b-4550-d64a-a1a2b24c25d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["가사 파일 수 : 49\n","가사의 줄 수 : 187088\n"]}],"source":["import glob\n","import os\n","import re\n","import tensorflow as tf\n","\n","tf.random.set_seed(1234)\n","\n","\n","txt_file_path = '/content/drive/MyDrive/aiffel/ex4/lyrics/*'\n","\n","txt_list = glob.glob(txt_file_path)\n","print(f\"가사 파일 수 : {len(txt_list)}\")\n","raw_corpus = []\n","\n","for txt_file in txt_list:\n","    with open(txt_file, \"r\") as f:\n","        raw = f.read().splitlines()\n","        raw_corpus.extend(raw)\n","\n","print(f\"가사의 줄 수 : {len(raw_corpus)}\")"]},{"cell_type":"markdown","metadata":{"id":"n9ZDmClfmGn5"},"source":[""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2115,"status":"ok","timestamp":1627469245121,"user":{"displayName":"장수완","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcHOjw1DJMH5S_Hl_Wuh_QCdDQy5hTTbQHK9YHDEQ=s64","userId":"01976359756172135532"},"user_tz":-540},"id":"p8LDLlskh5Ch","outputId":"cf38060a-25f6-47b8-803b-ddbb4a8c5b9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["['\u003cstart\u003e just before our love got lost you said \u003cend\u003e', '\u003cstart\u003e i am as constant as a northern star and i said \u003cend\u003e', '\u003cstart\u003e constantly in the darkness \u003cend\u003e', \"\u003cstart\u003e where's that at \u003cend\u003e\", \"\u003cstart\u003e if you want me i'll be in the bar on the back of a cartoon coaster \u003cend\u003e\"]\n"]}],"source":["def preprocess_sentence(sentence):\n","    sentence = sentence.lower().strip()\n","    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n","    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n","    sentence = re.sub(r\"[^a-zA-Z'?.!,¿]+\", \" \", sentence)\n","    sentence = sentence.strip()\n","    sentence = '\u003cstart\u003e ' + sentence + ' \u003cend\u003e'\n","    return sentence\n","\n","corpus = []\n","\n","for sentence in raw_corpus:\n","    if len(sentence) == 0: continue\n","    if sentence[-1] == \":\": continue\n","    if sentence.startswith('('): continue\n","    if sentence.startswith('['): continue\n","    preprocessed_sentence = preprocess_sentence(sentence)\n","    # if sentence.startswith('('):\n","    #     print(sentence, preprocessed_sentence)\n","    # if 'll' in preprocessed_sentence.split():\n","    #     print(sentence)\n","    # break\n","    # if preprocessed_sentence:\n","    corpus.append(preprocessed_sentence)\n","    \n","print(corpus[:5])"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4570,"status":"ok","timestamp":1627469249690,"user":{"displayName":"장수완","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcHOjw1DJMH5S_Hl_Wuh_QCdDQy5hTTbQHK9YHDEQ=s64","userId":"01976359756172135532"},"user_tz":-540},"id":"siPGliZ2h9rq"},"outputs":[],"source":["def tokenize(corpus):\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","        num_words=12000, \n","        filters=' ',\n","        oov_token=\"\u003cunk\u003e\",\n","    )\n","    tokenizer.fit_on_texts(corpus)\n","    tensor = tokenizer.texts_to_sequences(corpus)   \n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n","    \n","    return tensor, tokenizer\n","tensor, tokenizer = tokenize(corpus)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":390,"status":"ok","timestamp":1627469250071,"user":{"displayName":"장수완","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcHOjw1DJMH5S_Hl_Wuh_QCdDQy5hTTbQHK9YHDEQ=s64","userId":"01976359756172135532"},"user_tz":-540},"id":"YUAYmoe_m01E"},"outputs":[],"source":["src_input = tensor[:, :-1]\n","tgt_input = tensor[:, 1:]\n","from sklearn.model_selection import train_test_split\n","enc_train, enc_val, dec_train, dec_val = \\\n","\ttrain_test_split(src_input, tgt_input, test_size=0.2, random_state=1234)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1627469250071,"user":{"displayName":"장수완","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcHOjw1DJMH5S_Hl_Wuh_QCdDQy5hTTbQHK9YHDEQ=s64","userId":"01976359756172135532"},"user_tz":-540},"id":"6QzpBV7sm4sD","outputId":"dfafebe7-4394-424a-fb45-30e7f23057d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Source Train: (137132, 14)\n","Target Train: (137132, 14)\n"]}],"source":["print(\"Source Train:\", enc_train.shape)\n","print(\"Target Train:\", dec_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"zKH-z7AWm6r_"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","34/34 [==============================] - 17s 400ms/step - loss: 6.2996 - val_loss: 4.5955\n","Epoch 2/5\n","34/34 [==============================] - 13s 376ms/step - loss: 4.5373 - val_loss: 4.4850\n","Epoch 3/5\n","34/34 [==============================] - 13s 376ms/step - loss: 4.4574 - val_loss: 4.4366\n","Epoch 4/5\n","34/34 [==============================] - 13s 377ms/step - loss: 4.4120 - val_loss: 4.3708\n","Epoch 5/5\n","34/34 [==============================] - 13s 376ms/step - loss: 4.3115 - val_loss: 4.2512\n","hidden_size1 : 256, hidden_size2 : 256, val_loss : 4.595523357391357\n","Epoch 1/5\n","34/34 [==============================] - 24s 598ms/step - loss: 5.8755 - val_loss: 4.6546\n","Epoch 2/5\n","34/34 [==============================] - 19s 574ms/step - loss: 4.5528 - val_loss: 4.4593\n","Epoch 3/5\n","34/34 [==============================] - 19s 573ms/step - loss: 4.3239 - val_loss: 4.1507\n","Epoch 4/5\n","34/34 [==============================] - 19s 573ms/step - loss: 3.9835 - val_loss: 3.8358\n","Epoch 5/5\n","34/34 [==============================] - 19s 573ms/step - loss: 3.7879 - val_loss: 3.7526\n","hidden_size1 : 256, hidden_size2 : 512, val_loss : 4.65460205078125\n","Epoch 1/5\n","34/34 [==============================] - 40s 1s/step - loss: 5.5248 - val_loss: 4.3678\n","Epoch 2/5\n","34/34 [==============================] - 35s 1s/step - loss: 4.0335 - val_loss: 3.7942\n","Epoch 3/5\n","34/34 [==============================] - 35s 1s/step - loss: 3.7410 - val_loss: 3.7123\n","Epoch 4/5\n","34/34 [==============================] - 35s 1s/step - loss: 3.6802 - val_loss: 3.6539\n","Epoch 5/5\n","34/34 [==============================] - 35s 1s/step - loss: 3.6126 - val_loss: 3.5903\n","hidden_size1 : 256, hidden_size2 : 1024, val_loss : 4.367781162261963\n","Epoch 1/5\n","34/34 [==============================] - 88s 2s/step - loss: 5.2458 - val_loss: 4.1564\n","Epoch 2/5\n","34/34 [==============================] - 76s 2s/step - loss: 3.8976 - val_loss: 3.7459\n","Epoch 3/5\n","34/34 [==============================] - 76s 2s/step - loss: 3.7057 - val_loss: 3.6895\n","Epoch 4/5\n","34/34 [==============================] - 76s 2s/step - loss: 3.6454 - val_loss: 3.6104\n","Epoch 5/5\n","34/34 [==============================] - 76s 2s/step - loss: 3.5601 - val_loss: 3.5425\n","hidden_size1 : 256, hidden_size2 : 2048, val_loss : 4.15635347366333\n","Epoch 1/5\n","34/34 [==============================] - 19s 468ms/step - loss: 6.1131 - val_loss: 4.5744\n","Epoch 2/5\n","34/34 [==============================] - 15s 442ms/step - loss: 4.5083 - val_loss: 4.4578\n","Epoch 3/5\n","34/34 [==============================] - 15s 443ms/step - loss: 4.4371 - val_loss: 4.4129\n","Epoch 4/5\n","34/34 [==============================] - 15s 443ms/step - loss: 4.3802 - val_loss: 4.3310\n","Epoch 5/5\n","34/34 [==============================] - 15s 444ms/step - loss: 4.2811 - val_loss: 4.1910\n","hidden_size1 : 512, hidden_size2 : 256, val_loss : 4.574446201324463\n","Epoch 1/5\n","34/34 [==============================] - 26s 672ms/step - loss: 5.6757 - val_loss: 4.6064\n","Epoch 2/5\n","34/34 [==============================] - 22s 649ms/step - loss: 4.5244 - val_loss: 4.4379\n","Epoch 3/5\n","34/34 [==============================] - 22s 649ms/step - loss: 4.3292 - val_loss: 4.2082\n","Epoch 4/5\n","34/34 [==============================] - 22s 649ms/step - loss: 4.1463 - val_loss: 4.0031\n","Epoch 5/5\n","34/34 [==============================] - 22s 649ms/step - loss: 3.9156 - val_loss: 3.8216\n","hidden_size1 : 512, hidden_size2 : 512, val_loss : 4.606404781341553\n","Epoch 1/5\n","34/34 [==============================] - 44s 1s/step - loss: 5.3853 - val_loss: 4.4409\n","Epoch 2/5\n","34/34 [==============================] - 38s 1s/step - loss: 4.0850 - val_loss: 3.8501\n","Epoch 3/5\n","34/34 [==============================] - 38s 1s/step - loss: 3.7661 - val_loss: 3.7296\n","Epoch 4/5\n","34/34 [==============================] - 38s 1s/step - loss: 3.7027 - val_loss: 3.6925\n","Epoch 5/5\n","34/34 [==============================] - 38s 1s/step - loss: 3.6557 - val_loss: 3.6337\n","hidden_size1 : 512, hidden_size2 : 1024, val_loss : 4.4409332275390625\n","Epoch 1/5\n","34/34 [==============================] - 92s 2s/step - loss: 5.1000 - val_loss: 4.0701\n","Epoch 2/5\n","34/34 [==============================] - 80s 2s/step - loss: 3.8468 - val_loss: 3.7322\n","Epoch 3/5\n","34/34 [==============================] - 80s 2s/step - loss: 3.6973 - val_loss: 3.6862\n","Epoch 4/5\n","34/34 [==============================] - 80s 2s/step - loss: 3.6391 - val_loss: 3.6089\n","Epoch 5/5\n","34/34 [==============================] - 80s 2s/step - loss: 3.5571 - val_loss: 3.5410\n","hidden_size1 : 512, hidden_size2 : 2048, val_loss : 4.070143699645996\n","Epoch 1/5\n","34/34 [==============================] - 28s 682ms/step - loss: 5.8581 - val_loss: 4.5265\n","Epoch 2/5\n","34/34 [==============================] - 22s 656ms/step - loss: 4.4709 - val_loss: 4.4329\n","Epoch 3/5\n","34/34 [==============================] - 22s 655ms/step - loss: 4.3924 - val_loss: 4.3390\n","Epoch 4/5\n","34/34 [==============================] - 22s 655ms/step - loss: 4.3042 - val_loss: 4.3458\n","Epoch 5/5\n","34/34 [==============================] - 22s 655ms/step - loss: 4.2368 - val_loss: 4.1415\n","hidden_size1 : 1024, hidden_size2 : 256, val_loss : 4.526468753814697\n","Epoch 1/5\n","34/34 [==============================] - 35s 908ms/step - loss: 5.4882 - val_loss: 4.5731\n","Epoch 2/5\n","34/34 [==============================] - 30s 886ms/step - loss: 4.4901 - val_loss: 4.4053\n","Epoch 3/5\n","34/34 [==============================] - 30s 885ms/step - loss: 4.3083 - val_loss: 4.2207\n","Epoch 4/5\n","34/34 [==============================] - 30s 885ms/step - loss: 4.0754 - val_loss: 3.9143\n","Epoch 5/5\n","34/34 [==============================] - 30s 885ms/step - loss: 3.8426 - val_loss: 3.7902\n","hidden_size1 : 1024, hidden_size2 : 512, val_loss : 4.5731377601623535\n","Epoch 1/5\n","34/34 [==============================] - 54s 1s/step - loss: 5.3398 - val_loss: 4.3211\n","Epoch 2/5\n","34/34 [==============================] - 47s 1s/step - loss: 4.1436 - val_loss: 3.9193\n","Epoch 3/5\n","34/34 [==============================] - 47s 1s/step - loss: 3.7846 - val_loss: 3.7217\n","Epoch 4/5\n","34/34 [==============================] - 47s 1s/step - loss: 3.6906 - val_loss: 3.6751\n","Epoch 5/5\n","34/34 [==============================] - 47s 1s/step - loss: 3.6367 - val_loss: 3.6099\n","hidden_size1 : 1024, hidden_size2 : 1024, val_loss : 4.321094989776611\n","Epoch 1/5\n","34/34 [==============================] - 105s 3s/step - loss: 5.0472 - val_loss: 4.1924\n","Epoch 2/5\n","34/34 [==============================] - 92s 3s/step - loss: 3.9470 - val_loss: 3.7807\n","Epoch 3/5\n","34/34 [==============================] - 92s 3s/step - loss: 3.7183 - val_loss: 3.6965\n","Epoch 4/5\n","34/34 [==============================] - 92s 3s/step - loss: 3.6610 - val_loss: 3.6428\n","Epoch 5/5\n","34/34 [==============================] - 92s 3s/step - loss: 3.5896 - val_loss: 3.5665\n","hidden_size1 : 1024, hidden_size2 : 2048, val_loss : 4.192434787750244\n","Epoch 1/5\n","34/34 [==============================] - 57s 1s/step - loss: 5.7385 - val_loss: 4.4829\n","Epoch 2/5\n","34/34 [==============================] - 44s 1s/step - loss: 4.4402 - val_loss: 4.4023\n","Epoch 3/5\n","34/34 [==============================] - 45s 1s/step - loss: 4.3635 - val_loss: 4.3518\n","Epoch 4/5\n","34/34 [==============================] - 45s 1s/step - loss: 4.2779 - val_loss: 4.1790\n","Epoch 5/5\n","34/34 [==============================] - 45s 1s/step - loss: 4.0994 - val_loss: 4.0131\n","hidden_size1 : 2048, hidden_size2 : 256, val_loss : 4.482914924621582\n","Epoch 1/5\n","34/34 [==============================] - 65s 2s/step - loss: 5.2875 - val_loss: 4.5235\n","Epoch 2/5\n","34/34 [==============================] - 54s 2s/step - loss: 4.4370 - val_loss: 4.3711\n","Epoch 3/5\n","34/34 [==============================] - 54s 2s/step - loss: 4.2747 - val_loss: 4.2176\n","Epoch 4/5\n","34/34 [==============================] - 54s 2s/step - loss: 4.1130 - val_loss: 3.9432\n","Epoch 5/5\n","34/34 [==============================] - 54s 2s/step - loss: 3.8542 - val_loss: 3.7951\n","hidden_size1 : 2048, hidden_size2 : 512, val_loss : 4.523513317108154\n","Epoch 1/5\n","34/34 [==============================] - 87s 2s/step - loss: 5.1747 - val_loss: 4.3609\n","Epoch 2/5\n","34/34 [==============================] - 74s 2s/step - loss: 4.1813 - val_loss: 4.0471\n","Epoch 3/5\n","34/34 [==============================] - 74s 2s/step - loss: 3.9095 - val_loss: 3.7688\n","Epoch 4/5\n","34/34 [==============================] - 74s 2s/step - loss: 3.7101 - val_loss: 3.6807\n","Epoch 5/5\n","34/34 [==============================] - 74s 2s/step - loss: 3.6524 - val_loss: 3.6314\n","hidden_size1 : 2048, hidden_size2 : 1024, val_loss : 4.360922336578369\n","Epoch 1/5\n","34/34 [==============================] - 144s 4s/step - loss: 5.1678 - val_loss: 4.3126\n","Epoch 2/5\n","34/34 [==============================] - 125s 4s/step - loss: 4.1783 - val_loss: 4.1229\n","Epoch 3/5\n","34/34 [==============================] - 125s 4s/step - loss: 4.0867 - val_loss: 4.0945\n","Epoch 4/5\n","34/34 [==============================] - 125s 4s/step - loss: 3.9698 - val_loss: 3.8423\n","Epoch 5/5\n","34/34 [==============================] - 125s 4s/step - loss: 3.7682 - val_loss: 3.7262\n","hidden_size1 : 2048, hidden_size2 : 2048, val_loss : 4.312628269195557\n"]}],"source":["VOCAB_SIZE = tokenizer.num_words + 1\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","\n","\n","class TextGenerator(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_size, hidden_size1, hidden_size2):\n","        super(TextGenerator, self).__init__()\n","        \n","        self.embedding = Embedding(vocab_size, embedding_size)\n","        self.rnn_1 = LSTM(hidden_size1, return_sequences=True)\n","        self.rnn_2 = LSTM(hidden_size2, return_sequences=True)\n","        self.linear = Dense(vocab_size)\n","        self.dropout = Dropout(0.2)\n","    def call(self, x):\n","        out = self.embedding(x)\n","        out = self.rnn_1(out)\n","        out = self.dropout(out)\n","        out = self.rnn_2(out)\n","        out = self.dropout(out)\n","        out = self.linear(out)\n","        \n","        return out\n","    \n","embedding_size = 256\n","hidden_size = 1024\n","\n","hidden_sizes1 = [256, 512, 1024, 2048]\n","hidden_sizes2 = [256, 512, 1024, 2048]\n","best_val_loss = 100\n","best_hidden_size1 = 0\n","best_hidden_size2 = 0\n","from itertools import product\n","# hidden_sizes = [256]\n","for hidden_size1, hidden_size2 in product(hidden_sizes1, hidden_sizes2):\n","    model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size1, hidden_size2)\n","    optimizer = tf.keras.optimizers.Adam()\n","\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","\n","    model.compile(loss=loss, optimizer=optimizer)\n","    history = model.fit(enc_train, dec_train, epochs=5, validation_data=(enc_val, dec_val), batch_size=4096)\n","    val_loss = history.history['val_loss'][0]\n","    print(f\"hidden_size1 : {hidden_size1}, hidden_size2 : {hidden_size2}, val_loss : {val_loss}\")\n","    if best_val_loss \u003e val_loss:\n","        best_val_loss = val_loss\n","        best_hidden_size1 = hidden_size1\n","        best_hidden_size2 = hidden_size2\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1627472548169,"user":{"displayName":"장수완","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcHOjw1DJMH5S_Hl_Wuh_QCdDQy5hTTbQHK9YHDEQ=s64","userId":"01976359756172135532"},"user_tz":-540},"id":"yBNf6EgO572n","outputId":"620e2059-8b7e-45ff-8de1-4427d47dff3c"},"outputs":[{"data":{"text/plain":["(3.8896186351776123, 1024)"]},"execution_count":25,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["best_val_loss, best_hidden_size"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1766950,"status":"ok","timestamp":1627471679528,"user":{"displayName":"장수완","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcHOjw1DJMH5S_Hl_Wuh_QCdDQy5hTTbQHK9YHDEQ=s64","userId":"01976359756172135532"},"user_tz":-540},"id":"YJ_NV2MrnkCy","outputId":"566b46ff-676b-4d4a-c85b-694af7ff9a47"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","4286/4286 [==============================] - 180s 41ms/step - loss: 3.3634 - val_loss: 3.0736\n","Epoch 2/10\n","4286/4286 [==============================] - 174s 41ms/step - loss: 2.9354 - val_loss: 2.8533\n","Epoch 3/10\n","4286/4286 [==============================] - 175s 41ms/step - loss: 2.6793 - val_loss: 2.7206\n","Epoch 4/10\n","4286/4286 [==============================] - 175s 41ms/step - loss: 2.4620 - val_loss: 2.6384\n","Epoch 5/10\n","4286/4286 [==============================] - 175s 41ms/step - loss: 2.2810 - val_loss: 2.5834\n","Epoch 6/10\n","4286/4286 [==============================] - 175s 41ms/step - loss: 2.1329 - val_loss: 2.5467\n","Epoch 7/10\n","4286/4286 [==============================] - 175s 41ms/step - loss: 2.0087 - val_loss: 2.5210\n","Epoch 8/10\n","4286/4286 [==============================] - 175s 41ms/step - loss: 1.9063 - val_loss: 2.5111\n","Epoch 9/10\n","4286/4286 [==============================] - 174s 41ms/step - loss: 1.8214 - val_loss: 2.5035\n","Epoch 10/10\n","4286/4286 [==============================] - 175s 41ms/step - loss: 1.7507 - val_loss: 2.5133\n"]},{"data":{"text/plain":["\u003ctensorflow.python.keras.callbacks.History at 0x7f5835998c50\u003e"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["optimizer = tf.keras.optimizers.Adam()\n","\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","model.compile(loss=loss, optimizer=optimizer)\n","model.fit(enc_train, dec_train, epochs=10, validation_data=(enc_val, dec_val))"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":267,"status":"ok","timestamp":1627471719033,"user":{"displayName":"장수완","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcHOjw1DJMH5S_Hl_Wuh_QCdDQy5hTTbQHK9YHDEQ=s64","userId":"01976359756172135532"},"user_tz":-540},"id":"Aly40Jx_nsL_"},"outputs":[],"source":["def generate_text(model, tokenizer, init_sentence=\"\u003cstart\u003e\", max_len=20):\n","    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n","    test_input = tokenizer.texts_to_sequences([init_sentence])\n","    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n","    end_token = tokenizer.word_index[\"\u003cend\u003e\"]\n","\n","    # 단어 하나씩 예측해 문장을 만듭니다\n","    #    1. 입력받은 문장의 텐서를 입력합니다\n","    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n","    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n","    #    4. 모델이 \u003cend\u003e를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n","    while True:\n","        # 1\n","        predict = model(test_tensor) \n","        # 2\n","        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n","        # 3 \n","        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n","        # 4\n","        if predict_word.numpy()[0] == end_token: break\n","        if test_tensor.shape[1] \u003e= max_len: break\n","\n","    generated = \"\"\n","    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n","    for word_index in test_tensor[0].numpy():\n","        generated += tokenizer.index_word[word_index] + \" \"\n","\n","    return generated"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":250,"status":"ok","timestamp":1627471729485,"user":{"displayName":"장수완","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcHOjw1DJMH5S_Hl_Wuh_QCdDQy5hTTbQHK9YHDEQ=s64","userId":"01976359756172135532"},"user_tz":-540},"id":"6wDLI6II35Ai","outputId":"019f9141-890b-4ec9-cbbe-259473075a9d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\u003cstart\u003e i love you , baby , i love you so much \u003cend\u003e '"]},"execution_count":16,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["generate_text(model, tokenizer, init_sentence=\"\u003cstart\u003e i love\", max_len=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxRl-1mA37b0"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO8+iSDLtm5eSFn1db1V7ZD","machine_shape":"hm","mount_file_id":"1vzFWNMU7wyENKRzJwPGA-kF5Bv_WpcRW","name":"Untitled1.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}